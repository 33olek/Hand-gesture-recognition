# Hand-gesture-recognition
using ai tools for recognizing different patterns in hand movement.

System rozpoznawania gestów ręki do sterowania komputerem 

Opis projektu 

W tym projekcie uczeń stworzy model widzenia komputerowego (Computer Vision), który będzie w czasie rzeczywistym analizował obraz z kamery i rozpoznawał gesty dłoni, np. otwartą dłoń, zaciśniętą pięść, gest "ok" czy "like". Rozpoznane gesty posłużą do sterowania prostymi funkcjami komputera, np. odtwarzaniem muzyki, przewijaniem slajdów w prezentacji czy sterowaniem głośnością. 

 
 

Główne cele projektu 

Detekcja gestów: Uczeń nauczy się, jak algorytmy mogą identyfikować i interpretować gesty, które są dynamicznymi sekwencjami ruchów. 

Praca w czasie rzeczywistym: Projekt będzie wymagał przetwarzania danych w czasie rzeczywistym, co jest świetnym ćwiczeniem z optymalizacji kodu. 

Zbieranie i etykietowanie danych: Uczeń będzie musiał samodzielnie stworzyć zbiór danych, nagrywając filmy, na których wykonuje różne gesty. To bardzo ważne, praktyczne doświadczenie w przygotowywaniu danych. 

Integracja z systemem operacyjnym: Uczeń pozna, jak w Pythonie sterować systemem operacyjnym, np. symulując naciśnięcia klawiszy czy kliknięcia myszy. 

 
 

Technologia 

Język programowania: Python 🐍. 

Biblioteki: 

TensorFlow lub PyTorch do implementacji i trenowania sieci neuronowej. 

OpenCV do przechwytywania obrazu z kamery i wstępnej obróbki. 

MediaPipe (od Google) to doskonała biblioteka do detekcji kluczowych punktów na dłoni, co znacznie ułatwia proces rozpoznawania gestów. 

PyAutoGUI do symulowania interakcji z systemem operacyjnym. 

 
 

Dlaczego ten projekt? 

Jest interaktywny i wizualny: Uczeń od razu widzi efekty swojej pracy, co jest bardzo motywujące. 

Ma praktyczne zastosowanie: Można go wykorzystać do tworzenia kreatywnych interfejsów, np. do sterowania grami lub prezentacjami. 

Wprowadza do zaawansowanych technik: Projekt uczy, jak radzić sobie z danymi sekwencyjnymi i jak budować systemy działające w czasie rzeczywistym. 

 
