# Hand-gesture-recognition
using ai tools for recognizing different patterns in hand movement.

System rozpoznawania gest贸w rki do sterowania komputerem 

Opis projektu 

W tym projekcie ucze stworzy model widzenia komputerowego (Computer Vision), kt贸ry bdzie w czasie rzeczywistym analizowa obraz z kamery i rozpoznawa gesty doni, np. otwart do, zacinit pi, gest "ok" czy "like". Rozpoznane gesty posu偶 do sterowania prostymi funkcjami komputera, np. odtwarzaniem muzyki, przewijaniem slajd贸w w prezentacji czy sterowaniem gonoci. 

 
 

G贸wne cele projektu 

Detekcja gest贸w: Ucze nauczy si, jak algorytmy mog identyfikowa i interpretowa gesty, kt贸re s dynamicznymi sekwencjami ruch贸w. 

Praca w czasie rzeczywistym: Projekt bdzie wymaga przetwarzania danych w czasie rzeczywistym, co jest wietnym wiczeniem z optymalizacji kodu. 

Zbieranie i etykietowanie danych: Ucze bdzie musia samodzielnie stworzy zbi贸r danych, nagrywajc filmy, na kt贸rych wykonuje r贸偶ne gesty. To bardzo wa偶ne, praktyczne dowiadczenie w przygotowywaniu danych. 

Integracja z systemem operacyjnym: Ucze pozna, jak w Pythonie sterowa systemem operacyjnym, np. symulujc nacinicia klawiszy czy kliknicia myszy. 

 
 

Technologia 

Jzyk programowania: Python . 

Biblioteki: 

TensorFlow lub PyTorch do implementacji i trenowania sieci neuronowej. 

OpenCV do przechwytywania obrazu z kamery i wstpnej obr贸bki. 

MediaPipe (od Google) to doskonaa biblioteka do detekcji kluczowych punkt贸w na doni, co znacznie uatwia proces rozpoznawania gest贸w. 

PyAutoGUI do symulowania interakcji z systemem operacyjnym. 

 
 

Dlaczego ten projekt? 

Jest interaktywny i wizualny: Ucze od razu widzi efekty swojej pracy, co jest bardzo motywujce. 

Ma praktyczne zastosowanie: Mo偶na go wykorzysta do tworzenia kreatywnych interfejs贸w, np. do sterowania grami lub prezentacjami. 

Wprowadza do zaawansowanych technik: Projekt uczy, jak radzi sobie z danymi sekwencyjnymi i jak budowa systemy dziaajce w czasie rzeczywistym. 

 
